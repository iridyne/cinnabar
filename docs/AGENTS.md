# Cinnabar (æœ±ç ‚) - Architecture & Design Documentation

## Project Overview

**Cinnabar** is a lightweight, offline-first, streaming speech-to-text input tool for Linux systems. The name "æœ±ç ‚" (cinnabar) refers to the red mineral mercury sulfide, symbolizing the transformation of raw audio input into refined text output.

### Core Objectives

- **Offline-First**: All processing happens locally using ONNX models
- **Streaming**: Real-time partial results with automatic endpoint detection
- **Lightweight**: Minimal dependencies, optimized for edge devices
- **Linux-Native**: Built specifically for Linux audio stack (ALSA/PipeWire via cpal)

## Architecture

### Actor Model Design

Cinnabar implements a concurrent actor-like architecture with two primary threads communicating via bounded channels:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Audio Thread   â”‚         â”‚ Inference Thread â”‚
â”‚                 â”‚         â”‚                  â”‚
â”‚  1. Capture     â”‚         â”‚  1. Receive      â”‚
â”‚  2. Mono Mix    â”‚ â”€â”€â”€â”€â”€â”€> â”‚  2. Decode       â”‚
â”‚  3. Resample    â”‚ Channel â”‚  3. Display      â”‚
â”‚  4. Send        â”‚         â”‚  4. Endpoint     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Thread Responsibilities

#### Audio Capture Thread
- Captures raw audio from default microphone via `cpal`
- Converts multi-channel audio to mono by averaging channels
- Resamples from hardware sample rate (44100/48000Hz) to 16000Hz
- Sends resampled chunks to inference thread via bounded channel

#### Inference Thread
- Receives audio chunks from channel
- Feeds samples to Sherpa-ONNX OnlineRecognizer
- Displays partial results during speech
- Detects sentence endpoints and displays final results
- Resets recognizer state after each sentence

## Critical Technical Decisions

### 1. Audio Resampling Strategy

**Problem**: Paraformer model requires exactly 16000Hz sample rate, but most hardware defaults to 44100Hz or 48000Hz.

**Solution**: Implemented `LinearResampler` with the following characteristics:

- **Algorithm**: Linear interpolation between adjacent samples
- **Stateful**: Maintains buffer to handle fractional sample positions across chunks
- **Efficient**: Single-pass processing with minimal memory overhead

**Implementation Details**:
```
Input:  44100 Hz stream (or 48000 Hz)
Output: 16000 Hz stream
Ratio:  2.75625 (44100/16000) or 3.0 (48000/16000)

For each output sample at position i:
  src_idx = i * ratio
  idx0 = floor(src_idx)
  idx1 = idx0 + 1
  frac = src_idx - idx0
  output[i] = input[idx0] * (1 - frac) + input[idx1] * frac
```

**Why Not Hardware Resampling?**
- Not all audio devices support 16kHz natively
- Software resampling ensures consistent behavior across hardware
- Provides control over resampling quality

### 2. Channel Architecture

**Bounded Channel (Capacity: 100)**
- Prevents unbounded memory growth if inference lags
- Backpressure mechanism: audio thread blocks if channel full
- Trade-off: 100 chunks â‰ˆ 6.25 seconds of audio buffer at 16kHz

### 3. Endpoint Detection

**Automatic Sentence Segmentation**:
- Enabled via `enable_endpoint: true` in recognizer config
- Model detects silence periods to determine sentence boundaries
- Triggers final result display and recognizer reset

**User Experience Flow**:
1. User speaks: `ğŸ¤” Thinking: æˆ‘è§‰å¾—...` (partial, updates in-place)
2. User pauses: `âœ… Final: æˆ‘è§‰å¾— Rust å¾ˆå¼ºã€‚` (final, new line)
3. Recognizer resets, ready for next sentence

### 4. Model Selection

**Sherpa-ONNX Streaming Paraformer (Bilingual ZH-EN)**
- **Type**: Streaming ASR (not batch)
- **Languages**: Chinese + English
- **Quantization**: INT8 for reduced model size
- **Files Required**:
  - `encoder.int8.onnx`: Encoder network
  - `decoder.int8.onnx`: Decoder network
  - `tokens.txt`: Vocabulary mapping

**Why Paraformer?**
- Alibaba's production-grade model
- Excellent Chinese recognition accuracy
- Streaming-capable (incremental decoding)
- Lightweight INT8 quantization

## Component Breakdown

### Dependencies

| Crate | Purpose | Version |
|-------|---------|---------|
| `cpal` | Cross-platform audio I/O | 0.15 |
| `sherpa-rs` | ONNX inference engine (Rust bindings) | 0.6 |
| `crossbeam-channel` | Lock-free MPSC channels | 0.5 |
| `anyhow` | Error handling | 1.0 |
| `clap` | CLI argument parsing | 4.5 |
| `ctrlc` | Signal handling | 3.4 |

### Key Structures

#### `LinearResampler`
```rust
struct LinearResampler {
    from_rate: f32,      // Source sample rate
    to_rate: f32,        // Target sample rate (16000)
    buffer: Vec<f32>,    // Stateful buffer for fractional samples
}
```

#### `Args`
```rust
struct Args {
    model_dir: PathBuf,  // Path to model files (default: ./models)
}
```

## Data Flow

### Audio Pipeline
```
Hardware Mic (44100Hz, Stereo)
    â†“
cpal InputCallback
    â†“
Mono Mixing (average channels)
    â†“
LinearResampler (44100Hz â†’ 16000Hz)
    â†“
Bounded Channel (capacity: 100)
    â†“
OnlineRecognizer.accept_waveform()
    â†“
OnlineRecognizer.decode_stream()
    â†“
Display (partial/final results)
```

### State Machine
```
[IDLE] â”€â”€speechâ”€â”€> [DECODING] â”€â”€silenceâ”€â”€> [ENDPOINT] â”€â”€resetâ”€â”€> [IDLE]
         â†“              â†“                       â†“
    (no output)   (partial text)         (final text)
```

## Performance Characteristics

### Latency
- **Audio Capture**: ~10ms (cpal buffer size)
- **Resampling**: <1ms per chunk
- **Inference**: ~50-100ms per decode (CPU-dependent)
- **Total**: ~60-110ms end-to-end latency

### Memory
- **Model Size**: ~40MB (INT8 quantized)
- **Runtime**: ~100MB (including audio buffers)
- **Channel Buffer**: ~6.25 seconds of audio

### CPU
- **Threads**: 2 (audio + inference)
- **ONNX Threads**: 4 (configurable via `num_threads`)
- **Target**: Single-core capable on modern CPUs

## Usage

### Setup
```bash
# Download model files
./setup_models.sh

# Build and run
cargo run --release

# Custom model directory
cargo run --release -- --model-dir /path/to/models
```

### Expected Output
```
ğŸ”¥ Cinnabar (æœ±ç ‚) - Streaming Speech-to-Text
Model: ./models
ğŸ¤ Microphone: 44100 Hz, 2 channels
âœ… Model loaded. Listening...

Press Ctrl+C to stop...

ğŸ¤” Thinking: æˆ‘è§‰å¾—
ğŸ¤” Thinking: æˆ‘è§‰å¾— Rust
ğŸ¤” Thinking: æˆ‘è§‰å¾— Rust å¾ˆå¼º
âœ… Final: æˆ‘è§‰å¾— Rust å¾ˆå¼ºã€‚

ğŸ‘‹ Goodbye!
```

## Future Enhancements

### Phase 1.5: Audio Device Management

**Current Limitation**:
- Only uses system default input device (`default_input_device()`)
- No device enumeration or selection capability
- No support for multiple microphones
- No device hot-plug detection

**Planned Features**:
- [ ] List all available audio input devices
- [ ] CLI argument for device selection (`--device <index>` or `--device <name>`)
- [ ] Interactive device selection menu
- [ ] Display device capabilities (sample rates, channels)
- [ ] Device hot-plug monitoring and auto-reconnect
- [ ] Save preferred device in config file

**Implementation**:
```rust
// Enumerate devices
let devices: Vec<_> = host.input_devices()?.collect();
for (idx, device) in devices.iter().enumerate() {
    println!("è®¾å¤‡ {}: {} ({:?})", idx, device.name()?, device.default_input_config()?);
}

// Select by index or name
let device = if let Some(idx) = args.device_index {
    host.input_devices()?.nth(idx).context("è®¾å¤‡ç´¢å¼•æ— æ•ˆ")?
} else if let Some(name) = args.device_name {
    host.input_devices()?.find(|d| d.name().ok() == Some(name)).context("è®¾å¤‡åç§°æ— æ•ˆ")?
} else {
    host.default_input_device().context("æœªæ‰¾åˆ°é»˜è®¤è®¾å¤‡")?
};
```

**CLI Arguments**:
- `--list-devices`: List all available input devices and exit
- `--device <index>`: Use device by index (from `--list-devices`)
- `--device-name <name>`: Use device by name

**Priority**: Medium (improves usability for multi-microphone setups)

### Phase 2: Virtual Keyboard Integration

#### Input Method Implementation Analysis

**Option A: Wayland Input Method Protocol (input-method-v2)**

*Architecture*:
```
Cinnabar â†’ zwp_input_method_v2 â†’ Compositor â†’ Target Application
```

*Requirements*:
- Implement `zwp_input_method_v2` protocol (not `text-input-v3`)
- Register as input method with compositor
- Handle input method lifecycle (activate/deactivate)
- Commit text via `commit_string` requests

*Pros*:
- No special permissions required (runs as user)
- Wayland-native, future-proof design
- Works across all Wayland compositors (GNOME, KDE, Sway)
- Proper integration with compositor input stack
- Supports pre-edit text (å€™é€‰è¯æ˜¾ç¤º)

*Cons*:
- **High complexity**: Protocol state machine management
- **Limited Rust ecosystem**: `wayland-protocols` doesn't include input-method-v2 by default
- **Compositor dependency**: Requires compositor support (not all support input-method-v2)
- **No X11 support**: Wayland-only solution
- **Debugging difficulty**: Protocol errors are hard to trace
- **Demo unfriendly**: Requires compositor configuration to register as input method

*Implementation Estimate*:
- Protocol bindings generation: Complex (manual `wayland-scanner` usage)
- State machine implementation: ~500-800 LOC
- Compositor registration: Requires system-level configuration
- **Verdict**: Too complex for MVP/demo phase

**Option B: uinput Virtual Keyboard (Recommended for MVP)**

*Architecture*:
```
Cinnabar â†’ /dev/uinput â†’ Kernel evdev â†’ X11/Wayland â†’ Target Application
```

*Requirements*:
- Access to `/dev/uinput` (input group membership or udev rule)
- Create virtual keyboard device via `evdev` crate
- Emit key events (press/release sequences)
- Handle Unicode input via compose sequences or XKB

*Pros*:
- **Simple implementation**: ~100-200 LOC
- **Mature Rust ecosystem**: `evdev` crate is well-maintained
- **Works everywhere**: X11, Wayland, even TTY
- **Easy debugging**: Can test with `evtest` tool
- **Demo-friendly**: Quick setup with `usermod -aG input $USER`
- **No compositor dependency**: Kernel-level solution

*Cons*:
- Requires group membership or udev rule (one-time setup)
- Not "Wayland-native" (but works perfectly on Wayland)
- Unicode input requires key sequence generation
- Potential security concern (can inject input to any application)

*Implementation Estimate*:
- Device creation: ~50 LOC
- Key event emission: ~100 LOC
- Unicode handling: ~50 LOC (via XKB compose)
- **Verdict**: Ideal for MVP, production-ready

#### Recommended Approach: uinput (Option B)

**Rationale**:
1. **MVP Priority**: Get working demo quickly
2. **Reliability**: Proven approach used by existing tools (ydotool, wtype)
3. **Compatibility**: Works on all Linux systems regardless of display server
4. **Maintainability**: Simple codebase, easy to debug

**Permission Setup**:
```bash
# One-time setup (requires logout/login)
sudo usermod -aG input $USER

# Or via udev rule (no logout required)
echo 'KERNEL=="uinput", GROUP="input", MODE="0660"' | sudo tee /etc/udev/rules.d/99-cinnabar.rules
sudo udevadm control --reload-rules && sudo udevadm trigger
```

**Tech Stack**:
- `evdev` (0.12) - Virtual keyboard device creation and event emission
- `x11rb` (0.13) or `global-hotkey` (0.6) - Hotkey listening (X11/Wayland agnostic)
- `tokio` (1.42) - Async runtime for non-blocking hotkey handling

**Future Migration Path**:
- Phase 2: Ship with uinput implementation
- Phase 3: Add optional Wayland input-method-v2 backend for users who prefer it
- Use runtime detection to choose backend automatically

### Phase 3: Advanced Features
- Voice activity detection (VAD) for power efficiency
- Multi-model support (Whisper, Conformer, etc.)
- Punctuation restoration
- Speaker diarization
- Custom vocabulary injection

**Potential Tech Stack**:
- `webrtc-vad` (0.4) - WebRTC VAD implementation (lightweight)
- `onnxruntime` (0.0.14) - Direct ONNX runtime for Silero VAD
- `whisper-rs` (0.12) - OpenAI Whisper Rust bindings
- `tokenizers` (0.20) - HuggingFace tokenizers for custom vocabulary
- `serde` + `serde_json` (1.0) - Configuration file serialization
- `notify` (7.0) - File system watching for model hot-reload

### Phase 4: GUI
- System tray indicator
- Visual feedback for listening state
- Configuration panel
- Model management UI

**Potential Tech Stack**:
- `egui` (0.30) - Immediate mode GUI (lightweight, ~2MB binary)
- `iced` (0.13) - Elm-inspired GUI framework (declarative)
- `gtk4-rs` (0.9) - GTK4 bindings (Linux-native look)
- `tauri` (2.1) - Web-based GUI with Rust backend
- `dioxus` (0.6) - React-like Rust GUI framework
- `tray-icon` (0.18) - System tray support
- `tokio` (1.42) - Async runtime for non-blocking UI

## Potential Challenges & Mitigation Strategies

### Audio Stack Compatibility

**Problem**: Linux audio landscape is fragmented (ALSA, PulseAudio, PipeWire, JACK)

**Risks**:
- `cpal` may not detect microphone on some systems
- Sample rate/format negotiation failures
- Permission issues accessing audio devices
- Latency variations across different audio servers

**Mitigation**:
- Test on multiple distributions (Arch, Ubuntu, Fedora)
- Provide fallback device selection via CLI argument
- Document audio group membership requirements (`usermod -aG audio $USER`)
- Add verbose audio debugging mode (`--audio-debug`)
- Consider direct ALSA/PipeWire bindings as fallback

### Model Management

**Problem**: 40MB+ model files not suitable for git, download reliability issues

**Risks**:
- Users may have slow/unreliable internet connections
- Model file corruption during download
- Version mismatches between code and models
- Storage constraints on embedded devices

**Mitigation**:
- Implement model checksum verification (SHA256)
- Support resumable downloads with progress bars
- Provide multiple mirror sources (GitHub Releases, Hugging Face, CDN)
- Add `--model-cache-dir` for custom storage locations
- Consider model quantization levels (INT8 vs FP16 vs FP32)

### Performance Bottlenecks

**Problem**: Real-time inference on low-end hardware

**Risks**:
- CPU can't keep up with 16kHz audio stream
- Memory pressure on systems with <2GB RAM
- Thermal throttling on fanless devices
- Battery drain on laptops

**Mitigation**:
- Implement adaptive quality modes (fast/balanced/accurate)
- Add CPU usage monitoring and warnings
- Support model hot-swapping to lighter variants
- Implement frame dropping with user notification
- Profile with `perf` and optimize hot paths

### Thread Synchronization Issues

**Problem**: Audio thread and inference thread coordination

**Risks**:
- Channel overflow causing audio drops
- Deadlocks during shutdown
- Race conditions in endpoint detection
- Memory leaks from unreleased streams

**Mitigation**:
- Add comprehensive unit tests for channel behavior
- Implement graceful shutdown with timeout
- Use `Arc<AtomicBool>` for cancellation (already done)
- Add memory leak detection in CI (`valgrind`, `heaptrack`)
- Stress test with long-running sessions (24h+)

### uinput Permission Requirements (Phase 2)

**Problem**: Virtual keyboard requires root or special permissions

**Risks**:
- Users reluctant to run as root
- `uinput` module not loaded by default
- SELinux/AppArmor blocking access
- Wayland security model restrictions

**Mitigation**:
- Create udev rules for non-root access: `/etc/udev/rules.d/99-cinnabar.rules`
- Provide systemd service template
- Document capability-based permissions (`CAP_SYS_ADMIN`)
- Consider D-Bus activation for privileged operations
- Implement Wayland input-method protocol as alternative

### Dependency Build Failures

**Problem**: `sherpa-rs` has complex native dependencies (ONNX Runtime)

**Risks**:
- CMake version mismatches
- Missing system libraries (protobuf, abseil)
- Cross-compilation difficulties
- Long build times (10+ minutes)

**Mitigation**:
- Provide pre-built binaries for common platforms
- Document exact dependency versions in `docs/BUILD.md`
- Use Docker for reproducible builds
- Consider static linking for distribution
- Add CI matrix for multiple distros

### Latency Accumulation

**Problem**: Multiple processing stages add latency

**Risks**:
- Audio callback â†’ resampling â†’ channel â†’ inference â†’ display
- User perceives lag between speech and text
- Endpoint detection delayed by buffering

**Mitigation**:
- Measure end-to-end latency with timestamps
- Optimize resampler buffer management
- Use smaller channel capacity (trade memory for latency)
- Profile with `tracing` spans
- Target <100ms P95 latency

### Model Accuracy Issues

**Problem**: Paraformer may struggle with accents, noise, domain-specific terms

**Risks**:
- Poor recognition for non-standard Mandarin
- Background noise causing false positives
- Technical jargon not in vocabulary
- Code-switching between Chinese and English

**Mitigation**:
- Implement custom vocabulary injection (Phase 3)
- Add noise suppression preprocessing
- Support multiple model backends (Whisper, Conformer)
- Provide confidence scores in output
- Allow user feedback loop for corrections

## Pre-Development Checklist

### Development Environment

- [ ] Rust 1.70+ with `rustfmt` and `clippy`
- [ ] CMake 3.20+ for sherpa-rs native build
- [ ] Audio testing setup (microphone, speakers)
- [ ] Multiple Linux VMs/containers (Arch, Ubuntu 22.04, Fedora 39)
- [ ] Performance profiling tools (`perf`, `flamegraph`, `heaptrack`)
- [ ] Audio analysis tools (`pavucontrol`, `qpwgraph`, `alsamixer`)

### Testing Infrastructure

- [ ] Unit test framework with `cargo test`
- [ ] Integration tests with recorded audio samples
- [ ] Benchmark suite with `criterion`
- [ ] CI/CD pipeline (GitHub Actions)
- [ ] Fuzzing setup for audio resampler (`cargo-fuzz`)
- [ ] Memory leak detection in CI

### Model Assets

- [ ] Model download automation (`setup_models.sh`)
- [ ] Checksum verification (SHA256)
- [ ] Multiple model variants (INT8, FP16, FP32)
- [ ] Model versioning strategy
- [ ] Fallback models for low-end hardware
- [ ] License compliance documentation

### Documentation

- [ ] Architecture documentation (this file)
- [ ] Build instructions for each distro
- [ ] Troubleshooting guide
- [ ] Performance tuning guide
- [ ] API documentation (if library mode)
- [ ] Contributing guidelines

### Security Considerations

- [ ] Audit dependencies with `cargo-audit`
- [ ] Review unsafe code blocks (resampler, FFI)
- [ ] Validate model file integrity
- [ ] Sandbox inference process (seccomp, landlock)
- [ ] Document privilege requirements
- [ ] Security policy for vulnerability reports

### Performance Baselines

- [ ] Establish latency targets (P50, P95, P99)
- [ ] Memory usage limits (<200MB steady state)
- [ ] CPU usage targets (<50% single core)
- [ ] Battery impact measurements
- [ ] Thermal characteristics on fanless devices

### Distribution Preparation

- [ ] Package for Arch AUR
- [ ] Debian/Ubuntu `.deb` package
- [ ] Fedora `.rpm` package
- [ ] Flatpak manifest
- [ ] AppImage build
- [ ] Static binary with musl

## Design Philosophy

1. **Simplicity First**: CLI MVP before GUI complexity
2. **Offline Privacy**: No cloud dependencies, all local processing
3. **Rust Safety**: Memory safety without garbage collection overhead
4. **Linux Native**: Embrace Linux audio stack, don't abstract it away
5. **Production Ready**: Industry-grade code standards from day one

## Technical Constraints

- **Linux Only**: No Windows/macOS support (by design)
- **CPU Inference**: No GPU acceleration (yet)
- **Single Language Model**: One model loaded at a time
- **No VAD**: Continuous processing (power inefficient)

## Additional Tech Stack Considerations

### Testing & Quality Assurance
- `criterion` (0.5) - Benchmarking framework for performance regression testing
- `proptest` (1.5) - Property-based testing for audio resampling logic
- `mockall` (0.13) - Mock object generation for unit testing
- `rstest` (0.23) - Fixture-based testing framework
- `insta` (1.41) - Snapshot testing for recognition results

### Performance & Optimization
- `rayon` (1.10) - Data parallelism for batch processing
- `parking_lot` (0.12) - Faster synchronization primitives
- `mimalloc` (0.1) - Microsoft's high-performance allocator
- `flate2` (1.0) - Model compression/decompression
- `memmap2` (0.9) - Memory-mapped file I/O for large models

### Logging & Observability
- `tracing` (0.1) - Structured logging and diagnostics
- `tracing-subscriber` (0.3) - Log formatting and filtering
- `syslog` (7.0) - Linux syslog integration
- `metrics` (0.24) - Application metrics collection

### Configuration & Persistence
- `toml` (0.8) - Configuration file format
- `directories` (5.0) - XDG base directory specification
- `rusqlite` (0.32) - SQLite for recognition history/cache
- `config` (0.14) - Layered configuration management

### GPU Acceleration (Future)
- `ort` (2.0) - ONNX Runtime with CUDA/TensorRT support
- `cudarc` (0.12) - CUDA bindings for custom kernels
- `wgpu` (23.0) - WebGPU for cross-platform GPU compute

### Audio Processing Enhancements
- `rubato` (0.16) - High-quality audio resampling (alternative to LinearResampler)
- `dasp` (0.11) - Digital audio signal processing primitives
- `hound` (3.5) - WAV file I/O for debugging/testing
- `opus` (0.3) - Opus codec for audio compression

### IPC & Integration
- `dbus` (0.9) - D-Bus integration for desktop notifications
- `zbus` (5.1) - Modern async D-Bus library
- `libpulse-binding` (2.28) - Direct PulseAudio integration
- `pipewire` (0.8) - Native PipeWire API bindings

## References

- [Sherpa-ONNX Documentation](https://k2-fsa.github.io/sherpa/onnx/)
- [Paraformer Paper](https://arxiv.org/abs/2206.08317)
- [cpal Documentation](https://docs.rs/cpal/)
- [Linux Audio Stack](https://wiki.archlinux.org/title/Sound_system)

---

## Appendix A: FFI Migration & Debugging Lessons

### é—®é¢˜èƒŒæ™¯

åœ¨å°† Cinnabar ä» sherpa-rs è¿ç§»åˆ°ç›´æ¥ä½¿ç”¨ sherpa-onnx C FFI æ—¶ï¼Œé‡åˆ°äº†æŒç»­çš„æ®µé”™è¯¯ï¼ˆSIGSEGVï¼‰é—®é¢˜ã€‚ç¨‹åºèƒ½å¤ŸæˆåŠŸåŠ è½½æ¨¡å‹ã€åˆ›å»ºæµå¯¹è±¡ã€æ£€æµ‹éº¦å…‹é£ï¼Œä½†åœ¨å¤„ç†éŸ³é¢‘æ•°æ®æ—¶ç«‹å³å´©æºƒã€‚

### æ ¹æœ¬åŸå› 

#### 1. FFI ç”Ÿå‘½å‘¨æœŸç®¡ç†é”™è¯¯ï¼ˆä¸»è¦åŸå› ï¼‰

**é—®é¢˜ä»£ç **ï¼š
```rust
impl OnlineRecognizer {
    pub fn new(...) -> anyhow::Result<Self> {
        unsafe {
            let encoder_c = CString::new(encoder).unwrap();
            let decoder_c = CString::new(decoder).unwrap();
            let tokens_c = CString::new(tokens).unwrap();
            
            let config = SherpaOnnxOnlineRecognizerConfig {
                model_config: SherpaOnnxOnlineModelConfig {
                    paraformer: SherpaOnnxOnlineParaformerModelConfig {
                        encoder: encoder_c.as_ptr(),  // âŒ æ‚¬ç©ºæŒ‡é’ˆ
                        decoder: decoder_c.as_ptr(),  // âŒ æ‚¬ç©ºæŒ‡é’ˆ
                    },
                    tokens: tokens_c.as_ptr(),        // âŒ æ‚¬ç©ºæŒ‡é’ˆ
                    ...
                },
                ...
            };
            
            let recognizer = SherpaOnnxCreateOnlineRecognizer(&config);
            Ok(Self { recognizer })  // âŒ CString è¢«é”€æ¯ï¼ŒæŒ‡é’ˆå¤±æ•ˆ
        }
    }
}
```

**é—®é¢˜åˆ†æ**ï¼š
- `CString` å¯¹è±¡åœ¨å‡½æ•°ç»“æŸæ—¶è¢«é”€æ¯
- C API æŒæœ‰çš„æŒ‡é’ˆå˜æˆæ‚¬ç©ºæŒ‡é’ˆ
- å½“ sherpa-onnx å°è¯•è¯»å–æ¨¡å‹è·¯å¾„æ—¶è§¦å‘æ®µé”™è¯¯

**ä¿®å¤æ–¹æ¡ˆ**ï¼š
```rust
pub struct OnlineRecognizer {
    recognizer: *mut SherpaOnnxOnlineRecognizer,
    _encoder: CString,    // âœ… ä¿æŒç”Ÿå‘½å‘¨æœŸ
    _decoder: CString,
    _tokens: CString,
    _provider: CString,
    _decoding: CString,
}
```

#### 2. Sherpa-onnx å†…éƒ¨é‡é‡‡æ ·å™¨å´©æºƒï¼ˆæ¬¡è¦åŸå› ï¼‰

**é—®é¢˜ç°è±¡**ï¼š
```
/home/runner/work/sherpa-onnx/sherpa-onnx/sherpa-onnx/csrc/features.cc:AcceptWaveformImpl:104 Creating a resampler:
   in_sample_rate: 44100
   output_sample_rate: 16000

fish: Job 1, 'cargo run --release' terminated by signal SIGSEGV
```

**é—®é¢˜åˆ†æ**ï¼š
- Sherpa-onnx çš„ C++ é‡é‡‡æ ·å™¨åœ¨ Linuxï¼ˆç‰¹åˆ«æ˜¯ Arch/CachyOSï¼‰ä¸Šå­˜åœ¨ ABI å…¼å®¹æ€§é—®é¢˜
- å¯èƒ½ä¸ libc ç‰ˆæœ¬å·®å¼‚æˆ–å†…å­˜å¯¹é½é—®é¢˜ç›¸å…³

**ä¿®å¤æ–¹æ¡ˆ**ï¼š
```rust
// å¼ºåˆ¶ä½¿ç”¨ 16000Hz å•å£°é“ï¼Œè®© PipeWire å¤„ç†é‡é‡‡æ ·
let config = cpal::StreamConfig {
    channels: 1,
    sample_rate: cpal::SampleRate(16000),
    buffer_size: cpal::BufferSize::Default,
};
```

#### 3. FFI ç»“æ„ä½“å®šä¹‰ä¸å®Œæ•´

**é—®é¢˜ä»£ç **ï¼š
```rust
#[repr(C)]
pub struct SherpaOnnxOnlineRecognizerResult {
    pub text: *const c_char,  // âŒ ç¼ºå°‘å…¶ä»–å­—æ®µ
}
```

**æ­£ç¡®å®šä¹‰**ï¼ˆæ¥è‡ª C API å¤´æ–‡ä»¶ï¼‰ï¼š
```rust
#[repr(C)]
pub struct SherpaOnnxOnlineRecognizerResult {
    pub text: *const c_char,
    pub tokens: *const c_char,
    pub tokens_arr: *const *const c_char,
    pub timestamps: *const c_float,
    pub count: c_int,
    pub json: *const c_char,
}
```

### å…³é”®ç»éªŒæ•™è®­

#### 1. FFI ç”Ÿå‘½å‘¨æœŸç®¡ç†
- **è§„åˆ™**ï¼šC API æŒæœ‰çš„æŒ‡é’ˆå¿…é¡»åœ¨æ•´ä¸ªä½¿ç”¨æœŸé—´ä¿æŒæœ‰æ•ˆ
- **å®è·µ**ï¼šå°† `CString` å­˜å‚¨åœ¨ç»“æ„ä½“ä¸­ï¼Œè€Œä¸æ˜¯ä¸´æ—¶å˜é‡
- **æ£€æŸ¥**ï¼šä½¿ç”¨ Valgrind æˆ– AddressSanitizer æ£€æµ‹æ‚¬ç©ºæŒ‡é’ˆ

#### 2. FFI ç»“æ„ä½“å®šä¹‰
- **è§„åˆ™**ï¼šå¿…é¡»ä¸ C API å¤´æ–‡ä»¶å®Œå…¨ä¸€è‡´ï¼ˆå­—æ®µæ•°é‡ã€ç±»å‹ã€é¡ºåºï¼‰
- **å®è·µ**ï¼šç›´æ¥æŸ¥çœ‹ `.h` æ–‡ä»¶ï¼Œä¸è¦ä¾èµ–æ–‡æ¡£æˆ–çŒœæµ‹
- **å·¥å…·**ï¼šè€ƒè™‘ä½¿ç”¨ `bindgen` è‡ªåŠ¨ç”Ÿæˆç»‘å®š

#### 3. è°ƒè¯•ç­–ç•¥
```bash
# 1. æ£€æŸ¥å…±äº«åº“ç¬¦å·
nm -D libsherpa-onnx-c-api.so | grep SherpaOnnx

# 2. æŸ¥çœ‹ C API å¤´æ–‡ä»¶
cat sherpa-onnx/c-api/c-api.h | grep -A 20 "typedef struct"

# 3. ä½¿ç”¨ debug æ¨¡å¼è·å–æ›´å¤šä¿¡æ¯
cargo build && ./target/debug/cinnabar

# 4. æ£€æŸ¥åº“ä¾èµ–
ldd target/release/cinnabar

# 5. æŸ¥çœ‹ç³»ç»Ÿæ—¥å¿—ï¼ˆéœ€è¦ rootï¼‰
sudo dmesg | tail -20 | grep segfault
```

#### 4. sherpa-rs çš„å±€é™æ€§
- sherpa-rs 0.6.8 ä¸»è¦æ”¯æŒç¦»çº¿æ‰¹å¤„ç† APIï¼ˆ`OfflineStream`ï¼‰
- ç¼ºå°‘çœŸæ­£çš„æµå¼ APIï¼ˆ`OnlineStream`ï¼‰æ”¯æŒ
- éœ€è¦ç›´æ¥ä½¿ç”¨ sherpa-onnx C FFI æ‰èƒ½å®ç°çœŸæ­£çš„æµå¼è¯†åˆ«

#### 5. å¹³å°ç‰¹å®šé—®é¢˜
- Linux éŸ³é¢‘æ ˆï¼ˆALSA/PipeWireï¼‰ä¸ C++ åº“çš„ ABI å…¼å®¹æ€§
- ä¼˜å…ˆè®©ç³»ç»Ÿå¤„ç†éŸ³é¢‘æ ¼å¼è½¬æ¢ï¼Œé¿å…ä½¿ç”¨ç¬¬ä¸‰æ–¹åº“çš„é‡é‡‡æ ·å™¨
- åœ¨ Arch/CachyOS ç­‰æ»šåŠ¨å‘è¡Œç‰ˆä¸Šç‰¹åˆ«æ³¨æ„ ABI å…¼å®¹æ€§

### æœªæ¥æ”¹è¿›å»ºè®®

#### çŸ­æœŸ
- [x] æ·»åŠ éŸ³é¢‘é…ç½®å›é€€æœºåˆ¶ï¼ˆå¦‚æœ 16kHz ä¸æ”¯æŒï¼Œä½¿ç”¨æ‰‹åŠ¨é‡é‡‡æ ·ï¼‰
- [x] å®ç° rpath è‡ªåŠ¨é…ç½®ï¼Œé¿å…æ‰‹åŠ¨è®¾ç½® `LD_LIBRARY_PATH`
- [x] æ·»åŠ è®¾å¤‡æšä¸¾å’Œé€‰æ‹©åŠŸèƒ½

#### ä¸­æœŸ
- [ ] ä½¿ç”¨ `bindgen` è‡ªåŠ¨ç”Ÿæˆ FFI ç»‘å®š
- [ ] æ·»åŠ å•å…ƒæµ‹è¯•éªŒè¯ FFI è°ƒç”¨
- [ ] ç ”ç©¶ sherpa-onnx çš„çº¿ç¨‹å®‰å…¨æ€§

#### é•¿æœŸ
- [ ] è€ƒè™‘ä½¿ç”¨å…¶ä»– ASR å¼•æ“ï¼ˆVoskã€Whisperï¼‰ä½œä¸ºå¤‡é€‰
- [ ] ç­‰å¾… sherpa-rs å®˜æ–¹æ·»åŠ æµå¼ API æ”¯æŒ
- [ ] è´¡çŒ®ä¿®å¤åˆ°ä¸Šæ¸¸ sherpa-onnx é¡¹ç›®

### æŠ€æœ¯å€ºåŠ¡è®°å½•

| é—®é¢˜ | ä¼˜å…ˆçº§ | çŠ¶æ€ | ä½ç½® |
|------|--------|------|------|
| æ‰‹åŠ¨è®¾ç½® LD_LIBRARY_PATH | é«˜ | âœ… å·²ä¿®å¤ | build.rs |
| ç¡¬ç¼–ç  16kHz é…ç½® | ä¸­ | âœ… å·²æ”¹è¿› | src/main.rs + src/resampler.rs |
| ç¼ºå°‘è®¾å¤‡é€‰æ‹©åŠŸèƒ½ | ä¸­ | âœ… å·²å®ç° | src/main.rs |
| FFI ç»‘å®šæ‰‹åŠ¨ç»´æŠ¤ | ä½ | å¾…ä¼˜åŒ– | src/ffi/mod.rs |

---

**æœ€åæ›´æ–°**: 2026-02-03  
**ç‰ˆæœ¬**: 0.1.1 (Phase 1.5 å®Œæˆ)  
**çŠ¶æ€**: âœ… æ ¸å¿ƒåŠŸèƒ½å¯ç”¨ï¼ŒçŸ­æœŸæ”¹è¿›å·²å®Œæˆ